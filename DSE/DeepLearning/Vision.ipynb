{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434c9f2a-727c-43d6-9959-3bd5ebc93a8b",
   "metadata": {},
   "source": [
    "\n",
    "# Tensorflow: Image Classification.\n",
    "\n",
    "In image classification, we have a set of couples (input, output) and we are interested to get a predictor that can map inputs (images) and outputs (labels) correctly. For example, if you have a bunch of labeled images of dogs and cats, you can train a model to distinguish dogs from cats. Below, you have some important things to settle before starting training. \n",
    "\n",
    "\n",
    "1. The **training set**: a set of couples (input, output). We search for functions that are capable of mapping inputs to outputs for the whole training set.  \n",
    "2. The **test set**: To see whether our predictors generalize well, we use another set to test our predictors.\n",
    "3. The **predictor class**: The set of possible predictors. We search among the predictor class for good ones.\n",
    "4. The **loss functions**: The loss should be low for good predictors and should be high for bad ones. \n",
    "5. The **model**: When we combine a loss and a predictor class, we get a model.\n",
    "\n",
    "### Get The Data.\n",
    "\n",
    "1. Download the dataset.\n",
    "2. Split into train and test set.\n",
    "2. Define loading procedures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a1434d-6822-4a3d-a036-45ad39a92942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wget, zipfile, os, random\n",
    "\n",
    "if not os.path.isfile(\"data.zip\"): \n",
    "    print(\"downloading...\")\n",
    "    wget.download(\"https://storage.googleapis.com/kagglesdsdata/competitions/3362/31148/train.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1711182859&Signature=iJMiDxtrQKQposwCnqNIRnVzqHu7ovd7zcMM1awT23Sf5NycRXp4y6NujoxPId3sNXloON%2F%2BCwmb8CPFQjeRY%2BYvZmm9BxCLhtNHXFWKeDFv4eEBEPUkFEy3LXhpW2V0g%2FLjX50Cjg6h2xjtM%2BmeJeyPgf9vYfV7AUfHNNQn9iG%2FdeAfoySYWKl0YULS8S5ZHeatAdsM8VA%2F3xxACGmv8Sg4Wyc00%2BBG%2Fo6MVzj25CfXlb3nixpan9g9P8CSpnmBJc64HU1bXbAnZ1zJ%2Bl2qTUIS4CddIwCm4zFcrzDvFoOoFfuBedy9surDBC733NUjdaAjKKoghh8gWSTT7P3z9Q%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.zip\", \"data.zip\")\n",
    "\n",
    "if not (os.path.isdir(\"data\") and os.path.isdir(\"data/train\")): \n",
    "    print(\"extracting...\")\n",
    "    with zipfile.ZipFile(\"data.zip\", 'r') as file: file.extractall(\"./data/\")\n",
    "\n",
    "paths = list(map(lambda name:os.path.join(\"data/train\",name), os.listdir(\"data/train/\")))\n",
    "random.shuffle(paths)\n",
    "test_paths  = paths[:len(paths)//3]\n",
    "train_paths = paths[len(paths)//3+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305a30d-6933-4caf-9abc-9b08cb6d1286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "Image.open(random.choice(train_paths)).resize((256,256), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f49ba6e-7447-4b57-8e8b-1eb5d2c013af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random, PIL\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def to_standard_image(path, size=(64, 64)):\n",
    "    return tf.keras.utils.img_to_array(PIL.Image.open(path).resize(size, PIL.Image.NEAREST)).mean(-1)/255\n",
    "\n",
    "def to_standard_label(path): \n",
    "    return 0 if \"cat\" in path else 1\n",
    "\n",
    "def load_normalized_batch(paths, batch_size = 10, image_size = (64, 64)):\n",
    "    batch = random.choices(paths, k=batch_size)\n",
    "    X = np.stack([to_standard_image(p, size=image_size) for p in batch])\n",
    "    Y = np.array([to_standard_label(p) for p in batch])\n",
    "    return X,Y\n",
    "    \n",
    "X,Y = load_normalized_batch(train_paths)\n",
    "plt.imshow(X[0], cmap='gray')\n",
    "print(f\"label: {Y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc90a7-1beb-48cc-b7d9-e5168cce3cbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define A Model.\n",
    "\n",
    "In tensorflow, you can define a model in many ways. One of the most flexible ways to define models is extending [tf.keras.Model]. The `__init__` should define which component you are going to use. Instead, the `call` method should define how the pre-defined components interact.   \n",
    "\n",
    "In `tf.keras.layers` you can find a vast amount of layers. Some very common, some very specific. You can build a new layer using the predefined ones. Or, you can define new layers entirely using tensorflow Variables. \n",
    "\n",
    "#### Dense Layer\n",
    "For example one of the most common layer is the `tf.keras.layers.Dense`. It computes:\n",
    "\n",
    "$$g(xW^T + b)$$\n",
    "\n",
    "Where $x$ is the layer input, $x \\in \\mathbb{R}^{n}$. $W$ is a matrix of learnable variables, $W \\in \\mathbb{R}^{m\\times n}$. $b$ is a vector of learnable variables, $b \\in \\mathbb{R}^m$. $g$ is an activation function. Without $g$, the dense layer would be a simple linear layer. Both $g$ and $m$ are hyper-parameters of choice. Why hyper-parameters? if parameters defines a class of functions, hyper-parameters define a class of class of functions. Do not think about it too much, it is just a convenient way to say that it is a parameter that you can choose as you like, and it is not trained. Often, you can find a dense layer represented as:\n",
    "\n",
    "\n",
    "<center><img src=\"https://numenta.com/wp-content/uploads/2021/05/sparsityblog_1-600x231.png\" alt=\"drawing\" width=\"600\"/></center>\n",
    "\n",
    "### Convolution Layer\n",
    "\n",
    "[Convolution] is another deep learning layer. It was originally inspired by the structure of the human visual cortex. In practice, convolution layers work extremely well with visual tasks. The Convolution layer is already defined in tensorflow and you can use it easily. Below there is a simple gif showing a convolution operation. \n",
    "\n",
    "* the **kernel** is the sliding window that you see below. It is composed of trainable parameters. While it slides, it computes the element-wise multiplication between the kernel and the window.\n",
    "* the kernel is said to become **active** when it produces a high value. In practice, this means that it becomes active when it is multiplied against a window similar to the kernel.\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/1/19/2D_Convolution_Animation.gif\" alt=\"drawing\" width=\"400\"/></center>\n",
    "\n",
    "In modern architectures, convolution layers are stacked on top of each other. Layers closer to the input become active for simple shapes. The layers on top activate with complex patterns formed by the features below. The figure below shows some activation patterns for low/mid/high-level layers. \n",
    "\n",
    "<center><img src=\"https://d33wubrfki0l68.cloudfront.net/05c47b9b612f8b9f2f57cae4505a4773415f3f22/b9ed6/assets/convnets/cnn20.png\" alt=\"drawing\" width=\"400\"/></center>\n",
    "\n",
    "### Max Pooling Layer\n",
    "The [MaxPooling2D] layer is another common layer found in neural networks for vision. In practice, works similarly to the convolution layer. Instead of having a kernel of trainable parameters, it takes the maximum of each window.\n",
    "\n",
    "\n",
    "[MaxPooling2D]:https://keras.io/api/layers/pooling_layers/max_pooling2d/\n",
    "[Dense]:https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "[Convolution]:https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05822bf-bc9c-41e9-b3f1-2f58e3316f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "image_size = (64,64)\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, batch_size, image_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.reshape = tf.keras.layers.Reshape((128*128,))\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu') \n",
    "        self.maxp1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu') \n",
    "        self.maxp2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')\n",
    "        self.flat1 = tf.keras.layers.Flatten()\n",
    "        \n",
    "        self.dense1  = tf.keras.layers.Dense(64, activation=\"relu\")\n",
    "        self.dense2  = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.expand_dims(x, -1)\n",
    "        x = self.maxp1(self.conv1(x))\n",
    "        x = self.maxp2(self.conv2(x))\n",
    "        x = self.flat1(self.conv3(x))\n",
    "        x = self.dense2(self.dense1(x))\n",
    "        return x[:, 0]\n",
    "        \n",
    "lossfn = lambda preds, truths: tf.reduce_sum((preds - truths)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e05c554-8734-471c-9f51-dfbb71761d77",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2.3. Training Step\n",
    "\n",
    "Now we can define a training step. We need to do the following things:\n",
    "1. Feed data to the model.\n",
    "2. Compute gradients.\n",
    "3. Update model parameters (aka tensorflow variables).\n",
    "4. Compute additional metrics, such as accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0028af9-5463-45ef-949d-9d23acf3a16d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(X, Y, model):\n",
    "    \n",
    "    # register operations\n",
    "    with tf.GradientTape() as tape:\n",
    "        X = tf.cast(tf.convert_to_tensor(X), tf.float32)\n",
    "        Y = tf.cast(tf.convert_to_tensor(Y), tf.float32)\n",
    "        P = model(X, training=True)\n",
    "        loss = lossfn(Y, P)\n",
    "        \n",
    "    # compute gradients\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    # update parameters\n",
    "    for v,g in zip(model.trainable_variables, gradients): v.assign(v - 0.0001*g)\n",
    "        \n",
    "    # compute accuracy\n",
    "    acc = tf.reduce_sum(tf.cast(Y == tf.round(P), tf.int32))/X.shape[0]\n",
    "    \n",
    "    return loss.numpy(), acc.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c3bcf-8d5c-47c8-8a79-d9a6a8908733",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### Training the model\n",
    "To train, we just need to repeat the training step until we are satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331420c-11f8-4d35-9215-7b3d9b90c39c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MyModel(batch_size, image_size)\n",
    "for i in range(2000):\n",
    "    X,Y = load_normalized_batch(train_paths, batch_size=batch_size, image_size=image_size)\n",
    "    l,a = train_step(X, Y, model=model)\n",
    "    print(f\"\\r batch: {i}, loss: {l}, acc: {a}\", end=\"    \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65ae7e7-4e62-41ec-a8b5-cf3065b68b94",
   "metadata": {},
   "source": [
    "______\n",
    "### 3.2.4. Testing the model\n",
    "\n",
    "To test the model, we collect the metrics on the test set, without performing any training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651bff62-ba67-4c62-bfd9-7577569931d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "tp, fp, fn, tn = 0, 0, 0, 0\n",
    "random.shuffle(test_paths)\n",
    "paths = test_paths\n",
    "for i,p in enumerate(paths):\n",
    "    X = to_standard_image(p, size=image_size)\n",
    "    Y = to_standard_label(p)\n",
    "    P = tf.round(model(X.reshape(1,image_size[0],image_size[1]), training=True)).numpy()[0]\n",
    "\n",
    "    if Y == 1 and P == 1: tp += 1\n",
    "    if Y == 0 and P == 1: fp += 1\n",
    "    if Y == 1 and P == 0: fn += 1\n",
    "    if Y == 0 and P == 0: tn += 1\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    print(f\"\\r {i}/{len(paths)}, acc: {acc}\",end=\"\")\n",
    "\n",
    "print(f\"\\ntest accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e79f5c-b762-4dfb-a029-aa814d2e7209",
   "metadata": {},
   "source": [
    "_______\n",
    "### 3.2.5. Improving the Model.\n",
    "\n",
    "#### 3.2.5.1 Loss.\n",
    "\n",
    "All losses have one thing in common, they are big when there are errors and they are small when everything is right. By minimizing a loss, you are forcing your model to behave the way you want. However, it should be noted that different losses may impact the learning process differently. Ultimately, using the right loss for your task can lead to improvements and faster convergence. Unfortunately, knowing the right loss to use is not an easy task. Luckily, tensorflow already defines several losses that you can try out easily.\n",
    "\n",
    "One common loss for classification task is the [CategoricalCrossentropy].\n",
    "\n",
    "[CategoricalCrossentropy]:https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy\n",
    "______\n",
    "\n",
    "#### 3.2.5.2 Optimizer.\n",
    "\n",
    "Up until now to we update the model parameter by simply computing the partial derivatives of $w$ with respect to our model $L$.  \n",
    "$$ w \\leftarrow w - \\eta\\frac{\\partial L}{\\partial w} $$\n",
    "\n",
    "This little procedure is called optimizer. It turns out that there are a lot of ways you can define an optimizer. Instead of following blindly the current gradient you can average the current gradient with previous ones. You are still doing gradient descent but with a different optimization procedure. One popular optimizer that is often used is [Adam]. Adam, among many others, is already defined in tensorflow and can be adopted easily.\n",
    "\n",
    "______\n",
    "\n",
    "#### 3.2.5.3 Skip-Connections.\n",
    "\n",
    "You should know that a bigger model means that you can approximate more complex functions. However, in practice, it is not always the case. You will find yourself in many situations in which having more layers does actually hurt the results. Skip-connections are one of those mechanisms that can be useful to avoid this issue. given a layer $layer$ with input $x$ you can define a skip-connection for $x$ as follow:  \n",
    "\n",
    "$$x = x + layer(x)$$\n",
    "\n",
    "______\n",
    "\n",
    "### 3.2.5.4 Pretraining\n",
    "\n",
    "When we say nothing, tensorflow initializes the parameters randomly. This is perfectly fine for most scenarios. However, it is well known that some initializations are better than others. For example, if we were to train our model on a task for which we have many data available, we can hope that it will learn features general enough that can be useful for our task of interest. \n",
    "\n",
    "* When we train a model on a task with a huge dataset available with the intention of reusing its parameter later, we are doing **pretraining**.\n",
    "* When we train an already trained model on another task (or a different dataset), we are doing **fine-tuning**.\n",
    "\n",
    "Luckily, tensorflow has some pretrained models already defined so that we can just fine-tune them. Among these, one famous pretrained model is [ResNet]. ResNet relies heavily on both convolutions and skip-connections.\n",
    "______\n",
    "\n",
    "Finally, we can put everything toghether and train a much better model. \n",
    "\n",
    "[Adam]:https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
    "[ResNet]:https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d9fd1-0efe-4bca-b9da-b54f2f150116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.resnet  = tf.keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "        self.avg     = tf.keras.layers.AveragePooling2D(pool_size=(7, 7))\n",
    "        self.dense   = tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "        self.squeeze = tf.keras.layers.Reshape((2,))\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.squeeze(self.dense(self.avg(self.resnet(x))))\n",
    "    \n",
    "resnet  = ResNet()\n",
    "optim   = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "lossfn  = tf.keras.losses.CategoricalCrossentropy(from_logits=True, axis=-1,)\n",
    "\n",
    "### TRAIN LOOP ###\n",
    "for i in range(20):\n",
    "    batch = random.choices(train_paths, k = 10)                                                # load a\n",
    "    batchX = [tf.keras.preprocessing.image.load_img(x, target_size=(224,224)) for x in batch ] # batch\n",
    "    batchY = [[1,0] if \"cat\" in p else [0, 1]                                 for p in batch ] # worth of\n",
    "    batchX = [tf.keras.preprocessing.image.img_to_array(x)                    for x in batchX] # images\n",
    "    batchX = [tf.keras.applications.resnet50.preprocess_input(x)              for x in batchX] # \n",
    "    batchX = tf.stack(batchX)                                                                  #\n",
    "    batchY = tf.convert_to_tensor(batchY)                                                      #\n",
    "\n",
    "    \n",
    "    with tf.GradientTape() as tape:            # register the\n",
    "        batchP = resnet(batchX, training=True) # computational \n",
    "        loss   = lossfn(batchY, batchP)        # graph\n",
    "\n",
    "    # compute gradient and update the parameters\n",
    "    gradients = tape.gradient(loss, resnet.trainable_variables)\n",
    "    optim.apply_gradients(zip(gradients, resnet.trainable_variables))\n",
    "    \n",
    "    # compute accuracy score\n",
    "    acc = tf.reduce_sum(tf.cast(tf.argmax(batchY,-1) == tf.argmax(batchP,-1), tf.int32))/batchX.shape[0]\n",
    "\n",
    "    print(f\" train {i}/{20}, loss:{loss.numpy()}, acc:{acc.numpy()}\")\n",
    "    \n",
    "### TEST LOOP ###\n",
    "tp,fp,fn,tn = 0,0,0,0\n",
    "for i,p in enumerate(test_paths[:100]):\n",
    "    X = tf.keras.preprocessing.image.load_img(p, target_size=(224,224))\n",
    "    X = tf.keras.preprocessing.image.img_to_array(X)\n",
    "    X = tf.keras.applications.resnet50.preprocess_input(X)\n",
    "    X = tf.expand_dims(X,0)\n",
    "    Y = [1,0] if \"cat\" in p else [0,1]\n",
    "    Y = tf.convert_to_tensor(Y)\n",
    "    Y = tf.expand_dims(Y,0)    \n",
    "    \n",
    "    P = resnet(X, training=False)\n",
    "    \n",
    "    Y, P = tf.argmax(Y,-1).numpy(), tf.argmax(P,-1).numpy()\n",
    "\n",
    "    if Y == 1 and P == 1: tp += 1\n",
    "    if Y == 0 and P == 1: fp += 1\n",
    "    if Y == 1 and P == 0: fn += 1\n",
    "    if Y == 0 and P == 0: tn += 1\n",
    "    \n",
    "    print(f\"\\rtest {i}/{100}, acc:{(tp + tn) / (tp + tn + fp + fn)}\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573face-3f58-41b9-88a8-7384c040488d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = list(map(lambda name:os.path.join(\"data/test1\",name), os.listdir(\"data/test1/\")))\n",
    "image = tf.keras.preprocessing.image.load_img(random.choice(paths), target_size=(224,224))\n",
    "X = tf.keras.preprocessing.image.img_to_array(image)\n",
    "X = tf.keras.applications.resnet50.preprocess_input(X)\n",
    "X = tf.expand_dims(X,0)\n",
    "\n",
    "P = resnet(X, training=False)\n",
    "label2name = {0:\"cat\", 1:\"dog\"}\n",
    "\n",
    "print(f\"logit: {P.numpy().tolist()}\")\n",
    "print(f\"label: {label2name[tf.argmax(P,-1).numpy()[0]]}\")\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
