{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301bc4c5-828f-4522-a8f2-bb38ce91d12c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 11:43:47.025335: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 11:43:47.029494: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 11:43:47.080974: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-20 11:43:47.992006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-20 11:43:48.842111: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 11:43:48.842557: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ccf94a1-fa4c-4c51-a252-8a69ae897c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wget, zipfile, os, random\n",
    "\n",
    "# download dataset\n",
    "if not os.path.isfile(\"data.zip\"): \n",
    "    print(\"downloading...\")\n",
    "    wget.download(\"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/3362/31148/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1678299698&Signature=b6XuKNXvsSuBcv2SZYiTqcfr7Mc%2FjpSR%2BptWRsmjRTHr1vqLdnpC6k9YaLk%2BMRSmTeZcOXGFg21TGUyv9RR7TctRcWLW8WhIdibLM2BTLqc2YCM5ZXU9DkwYRypzgmXjZs4U%2B2n4AeOzO2w7CJFnxgjOeOtAamziNd5F07aiSap1A8b2PwtClwvsQA0kx1vp0HTtT99NsWpGFY310ZOMjRnpFK17ANh5UmYAaFeHm2RVyR%2FRRVcWbVTSWKhaEDLgppgdIREZ%2FGsXpybkFAqfWGqmHkDVEpty0E3BuyGGZ8DEkDphwjHlab824Waid0IpOeOgO6qAziK5fy22dCO0Pg%3D%3D&response-content-disposition=attachment%3B+filename%3Ddogs-vs-cats.zip\", \"data.zip\")\n",
    "\n",
    "# extract dataset\n",
    "if not (os.path.isdir(\"data\") and os.path.isdir(\"data/train\")): \n",
    "    print(\"extracting...\")\n",
    "    with zipfile.ZipFile(\"data.zip\"      , 'r') as file: file.extractall(\"./data/\")\n",
    "\n",
    "# get all train paths\n",
    "paths = list(map(lambda name:os.path.join(\"data/train\",name), os.listdir(\"data/train/\")))\n",
    "random.shuffle(paths)\n",
    "test_paths  = paths[:len(paths)//3]\n",
    "train_paths = paths[len(paths)//3+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e17a02e2-fb33-44b3-b0b6-afa8af28eedb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random, copy\n",
    "def batchfy(paths, batch_size):\n",
    "    #shuffle all paths\n",
    "    paths = copy.deepcopy(paths)\n",
    "    random.shuffle(paths)\n",
    "    \n",
    "    # batchfy\n",
    "    size = len(paths)\n",
    "    batches = size // batch_size\n",
    "    batches = [paths[i*batch_size:(i+1)*batch_size] for i in range(batches)]\n",
    "    \n",
    "    return batches\n",
    "\n",
    "\n",
    "def load_batch(paths):\n",
    "    tensor_images = tf.stack([tf.image.resize(tf.io.decode_image(tf.io.read_file(path),channels=3), (256,256))/256 for path in paths])\n",
    "    tensor_labels = tf.convert_to_tensor([[1,0] if path[11:14] == \"cat\" else [0,1] for path in paths], dtype=float)\n",
    "    return tensor_images, tensor_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfd30be8-abdc-44d7-8e43-3ec18b003bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class ConvBlock(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, kernel_size=(3,3), filters=16, strides=(2, 2)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv2a = tf.keras.layers.Conv2D(filters, (1, 1), strides=strides, )\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2b = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2c = tf.keras.layers.Conv2D(filters, (1, 1))\n",
    "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.convd = tf.keras.layers.Conv2D(filters, (1, 1), strides=strides)\n",
    "        self.bnd = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, z):\n",
    "        x = tf.nn.relu(self.bn2a(self.conv2a(z)))\n",
    "        x = tf.nn.relu(self.bn2b(self.conv2b(x)))\n",
    "        x = self.bn2c(self.conv2c(x))\n",
    "\n",
    "        z = self.convd(z)\n",
    "        z = self.bnd(z)\n",
    "\n",
    "        return tf.nn.relu(x + z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "676df341-178e-4481-b0d4-963a37828cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyResNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, (7, 7), strides=(2, 2))\n",
    "        self.bn_conv1 = tf.keras.layers.BatchNormalization()\n",
    "        self.max_pool = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))\n",
    "\n",
    "        self.c0 = ConvBlock()\n",
    "        self.c1 = ConvBlock()\n",
    "        self.c2 = ConvBlock()\n",
    "        self.c3 = ConvBlock()\n",
    "        self.c4 = ConvBlock()\n",
    "        \n",
    "        # GAP\n",
    "        self.gap = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.lin = tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "        \n",
    "    def call(self, x):\n",
    "      \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn_conv1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = self.c0(x)\n",
    "        x = self.c1(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.c3(x)\n",
    "        x = self.c4(x)\n",
    "\n",
    "        x = self.lin(self.gap(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6653b65-da25-44da-aea2-d5dd5918ad08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 11:46:08.264451: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 50331648 exceeds 10% of free system memory.\n",
      "2024-03-20 11:46:09.118248: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 256000000 exceeds 10% of free system memory.\n",
      "2024-03-20 11:46:09.239967: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 256000000 exceeds 10% of free system memory.\n",
      "2024-03-20 11:46:09.467506: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 256000000 exceeds 10% of free system memory.\n",
      "2024-03-20 11:46:09.846518: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 256000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch:0, batch:389/390, loss: 0.68166, acc: 0.59375, cma: 0.53602     \n",
      " epoch:1, batch:389/390, loss: 0.64798, acc: 0.60938, cma: 0.59808     \n",
      " epoch:2, batch:389/390, loss: 0.61035, acc: 0.64062, cma: 0.64415     \n",
      " epoch:3, batch:389/390, loss: 0.57530, acc: 0.73438, cma: 0.67352     \n",
      " epoch:4, batch:389/390, loss: 0.56810, acc: 0.71875, cma: 0.68910     \n",
      " epoch:5, batch:389/390, loss: 0.60341, acc: 0.67188, cma: 0.70809     \n",
      " epoch:6, batch:79/390, loss: 0.52935, acc: 0.73438, cma: 0.70977     "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "model = MyResNet()\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, axis=-1)\n",
    "\n",
    "for e in range(epochs):\n",
    "    cma = 0\n",
    "    \n",
    "    # shuffle and batch the dataset\n",
    "    batched_paths = batchfy(paths, batch_size)\n",
    "    \n",
    "    for i, batch in enumerate(batched_paths):\n",
    "        X, Y = load_batch(batch)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            P = model(X)\n",
    "            L = loss(Y, P)\n",
    "        \n",
    "        A = tf.reduce_mean(tf.cast(tf.argmax(P,-1) == tf.argmax(Y,-1), float))\n",
    "        cma = cma + (A-cma) / (i+1)\n",
    "        G = tape.gradient(L, model.trainable_variables)\n",
    "        optim.apply_gradients(zip(G, model.trainable_variables))\n",
    "\n",
    "        print(f\"\\r epoch:{e}, batch:{i}/{len(batched_paths)}, loss: {L.numpy():.5f}, acc: {A.numpy():.5f}, cma: {cma:.5f}\", end=\" \"*5)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
