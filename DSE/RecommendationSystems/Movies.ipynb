{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b527dff6-15c3-4d39-8ccb-709114e0e748",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predicting movie ratings\n",
    "\n",
    "One of the most common uses of big data is to predict what users want. This allows Google to show you relevant ads, Amazon to recommend relevant products, and Netflix to recommend movies that you might like. This lab will demonstrate how we can use Apache Spark to recommend movies to a user. We will start with some basic techniques, and then use the mllib library's Alternating Least Squares method to make more sophisticated predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcce0e1b-dbba-4538-8523-605a7433e292",
   "metadata": {},
   "source": [
    "## 1. Data Setup\n",
    "\n",
    "Before starting with the recommendation systems, we need to download the dataset and we need to do a little bit of pre-processing. \n",
    "\n",
    "### 1.1 Download\n",
    "Let's begin with downloading the dataset. If you have already a copy of the dataset you can skip this part. For this lab, we will use [movielens 25M stable benchmark rating dataset](https://files.grouplens.org/datasets/movielens/ml-25m.zip). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5cfd311-fcfa-4045-abe9-a2c98f3ffbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [......................................................................] 261978986 / 261978986"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dataset.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's start by downloading the dataset.\n",
    "import wget\n",
    "wget.download(url = \"https://files.grouplens.org/datasets/movielens/ml-25m.zip\", out = \"dataset.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0227049e-464b-4a20-985c-519f46b6dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's unzip the dataset\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"dataset.zip\", \"r\") as zfile:\n",
    "    zfile.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe01cbc8-3466-4285-aa32-a9e237387187",
   "metadata": {},
   "source": [
    "### 1.2 Dataset Format\n",
    "\n",
    "The following table highlights some data from `ratings.csv` (with comma-separated elements):\n",
    "\n",
    "| UserID | MovieID | Rating | Timestamp  |\n",
    "|--------|---------|--------|------------|\n",
    "|...|...|...|...|\n",
    "|3022|152836|5.0|1461788770|\n",
    "|3023|169|5.0|1302559971|\n",
    "|3023|262|5.0|1302559918|\n",
    "|...|...|...|...|\n",
    "\n",
    "The following table highlights some data from `movies.csv` (with comma-separated elements):\n",
    "\n",
    "| MovieID | Title   | Genres | \n",
    "|---------|---------|--------|\n",
    "|...|...|...|\n",
    "| 209133  |The Riot and the Dance (2018) | (no genres listed) |\n",
    "| 209135  |Jane B. by Agn√®s V. (1988) | Documentary\\|Fantasy |\n",
    "|...|...|...|\n",
    "\n",
    "The `Genres` field has the format\n",
    "\n",
    "`Genres1|Genres2|Genres3|...` or `(no generes listed)`\n",
    "\n",
    "The format of these files is uniform and simple, so we can easily parse them using python:\n",
    "- For each line in the rating dataset, we create a tuple of (UserID, MovieID, Rating). We drop\n",
    "the timestamp because we do not need it for this exercise.\n",
    "- For each line in the movies dataset, we create a tuple of (MovieID, Title). We drop the Genres\n",
    "because we do not need them for this exercise.\n",
    "\n",
    "### 1.3 Preprocessing\n",
    "\n",
    "We can begin to preprocess our data. This step includes: \n",
    "1) We should drop the timestamp, we do not need it.\n",
    "2) We should drop the genres, we do not need them.\n",
    "3) We should parse data according to their intended type. For example, the elements of rating should be floats.\n",
    "4) Each line should encode data in an easily processable format, like a tuple. \n",
    "5) We should filter the first line of both datasets (the header)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89921874-3b49-48df-82ef-44adf1aa2f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/f14/Devel/labs/DSE/RecommendationSystems/.venv-RS/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/22 09:40:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ataxia:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Python Spark SQL basic example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9bcad30760>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's intialize the spark session\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"Python Spark SQL basic example\") \\\n",
    "                    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b59fe5d-855d-427e-8e3a-284c83cba4b1",
   "metadata": {},
   "source": [
    "#### 1.3.1 Load The Data\n",
    "\n",
    "We can start by loading the dataset formatted as raw text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a7775c-6a66-4bb5-bbfe-4905376dbf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings --->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userId,movieId,rating,timestamp',\n",
      " '1,296,5.0,1147880044',\n",
      " '1,306,3.5,1147868817',\n",
      " '1,307,5.0,1147868828',\n",
      " '1,665,5.0,1147878820']\n",
      "\n",
      "movies --->\n",
      "['movieId,title,genres',\n",
      " '1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy',\n",
      " '2,Jumanji (1995),Adventure|Children|Fantasy',\n",
      " '3,Grumpier Old Men (1995),Comedy|Romance',\n",
      " '4,Waiting to Exhale (1995),Comedy|Drama|Romance']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "ratings_rdd = spark.sparkContext.textFile(name = \"ml-25m/ratings.csv\", minPartitions = 2)\n",
    "movies_rdd  = spark.sparkContext.textFile(name = \"ml-25m/movies.csv\" , minPartitions = 2)\n",
    "\n",
    "# let's have a peek a our dataset\n",
    "print(\"ratings --->\")\n",
    "pprint(ratings_rdd.take(5))\n",
    "\n",
    "print(\"\\nmovies --->\")\n",
    "pprint(movies_rdd.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac8f2f-fc72-4bcd-af9c-8d8836f18967",
   "metadata": {},
   "source": [
    "#### 1.3.2 SubSampling\n",
    "Since we have limited resources in terms of computation, sometimes, it is useful to work with only a fraction of the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "947d4441-438b-40f5-977f-dc21aeab6771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings_rdd: 998879, movies_rdd 62424\n"
     ]
    }
   ],
   "source": [
    "ratings_rdd = ratings_rdd.sample(withReplacement=False, fraction=1/25, seed=14).cache()\n",
    "movies_rdd  = movies_rdd .sample(withReplacement=False, fraction=1, seed=14).cache()\n",
    "\n",
    "print(f\"ratings_rdd: {ratings_rdd.count()}, movies_rdd {movies_rdd.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa2891-6b27-48c1-8ca4-04941388324b",
   "metadata": {},
   "source": [
    "#### 1.3.2 Parsing\n",
    "Here, we do the real preprocessing: dropping columns, parsing elements, and filtering the heading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "844bd4da-93b9-41fe-b339-f50f2cb45238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2rating(line):\n",
    "    \"\"\" Parse a line in the ratings dataset.\n",
    "    Args:\n",
    "        line (str): a line in the ratings dataset in the form of UserID,MovieID,Rating,Timestamp\n",
    "    Returns:\n",
    "        tuple[int,int,float]: (UserID, MovieID, Rating)\n",
    "    \"\"\"\n",
    "    userID, movieID, rating, *others = line.split(\",\")\n",
    "    try: return int(userID), int(movieID), float(rating),\n",
    "    except ValueError: return None\n",
    "\n",
    "def string2movie(line):\n",
    "    \"\"\" Parse a line in the movies dataset.\n",
    "    Args:\n",
    "        line (str): a line in the movies dataset in the form of MovieID,Title,Genres. \n",
    "                    Genres in the form of Genre1|Genre2|...\n",
    "    Returns:\n",
    "        tuple[int,str,list[str]]: (MovieID, Title, Genres)\n",
    "    \"\"\"\n",
    "    movieID, title, *others = line.split(\",\")\n",
    "    try: return int(movieID), title\n",
    "    except ValueError: return None\n",
    "\n",
    "ratings_rdd = ratings_rdd.map(string2rating).filter(lambda x:x!=None).cache()\n",
    "movies_rdd  = movies_rdd .map(string2movie ).filter(lambda x:x!=None).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efa4f3c9-a44f-4197-b461-884cda00304f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 998879 ratings and 62423 movies in the datasets\n",
      "Ratings: ---> \n",
      "[(1, 1653, 4.0), (1, 2068, 2.5), (1, 8973, 4.0)]\n",
      "Movies: ---> \n",
      "[(1, 'Toy Story (1995)'), (2, 'Jumanji (1995)'), (3, 'Grumpier Old Men (1995)')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {ratings_rdd.count()} ratings and {movies_rdd.count()} movies in the datasets\")\n",
    "print(f\"Ratings: ---> \\n{ratings_rdd.take(3)}\")\n",
    "print(f\"Movies: ---> \\n{movies_rdd.take(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa703e15-1995-43f2-af16-7d1599492dce",
   "metadata": {},
   "source": [
    "## 2. Basic Raccomandations\n",
    "\n",
    "\n",
    "### 2.1 Highest Average Rating.\n",
    "\n",
    "One way to recommend movies is to always recommend the movies with the highest average rating. In this section, we will use Spark to find the name, number of ratings, and the average rating of the 20 movies with the highest average rating and more than 500 reviews. We want to filter our movies with high ratings but fewer than or equal to 500 reviews because movies with few reviews may not have broad appeal to everyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20753f47-0e7d-43bd-9537-43f003812ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(72315, 3.050965250965251)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def averageRating(ratings):\n",
    "    \"\"\" Computes the average rating.\n",
    "        Args:\n",
    "            tuple[int, list[float]]: a MovieID with its list of ratings\n",
    "        Returns:\n",
    "            tuple[int, float]: returns the the MovieID with its average rating.\n",
    "    \"\"\" \n",
    "    return (ratings[0], sum(ratings[1]) / len(ratings[1]))\n",
    "\n",
    "rdd = ratings_rdd.map(lambda x:(x[0], x[2])).groupByKey() # group by MovieID\n",
    "rdd = rdd.filter(lambda x:len(x[1])>500)                  # filter movies with less than 500 reviews \n",
    "rdd = rdd.map(averageRating)                              # computes the average Rating\n",
    "rdd = rdd.sortBy(lambda x:x[1], ascending=False)\n",
    "\n",
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d155d45-e673-45d2-aaeb-a5ed91e7fd55",
   "metadata": {},
   "source": [
    "Ok, now we have the best (according to the average) popular (according to the number of reviews) movies. However, we can only see their MovieID. Let's convert the IDs into titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8bba8eb-31ec-44c1-a921-f8cd6aacfe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(\"Hell's Hinges (1916)\", 3.050965250965251)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.join(movies_rdd)\\\n",
    "   .map(lambda x:(x[1][1],x[1][0]))\\\n",
    "   .sortBy(lambda x:x[1], ascending=False)\\\n",
    "   .take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4d205-46f6-487d-9853-079602226959",
   "metadata": {},
   "source": [
    "### 2.2 Collaborative Filtering\n",
    "\n",
    "We are going to use a technique called collaborative filtering. Collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a person chosen randomly.\n",
    "\n",
    "At first, people rate different items (like videos, images, games). After that, the system is making predictions about a user's rating for an item, which the user has not rated yet. These predictions are built upon the existing ratings of other users, who have similar ratings with the active user.\n",
    "\n",
    "#### 2.2.1 Creating a Training Set\n",
    "\n",
    "Before we jump into using machine learning, we need to break up the `ratings_rdd` dataset into three pieces:\n",
    "\n",
    "* a training set (RDD), which we will use to train models,\n",
    "* a validation set (RDD), which we will use to choose the best model,\n",
    "* a test set (RDD), which we will use for estimating the predictive power of the recommender system.\n",
    "\n",
    "To randomly split the dataset into multiple groups, we can use the pyspark [randomSplit] transformation, which takes a list of splits with a seed and returns multiple RDDs.\n",
    "\n",
    "[randomSplit]:https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.RDD.randomSplit.html?highlight=randomsplit#pyspark.RDD.randomSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcd0b273-26d0-4951-bb5c-f6db1bf0593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 599932, validation: 199477, test: 199470\n",
      "training   samples:  [(1, 1653, 4.0), (1, 8973, 4.0), (2, 261, 0.5)]\n",
      "validation samples:  [(2, 1257, 5.0), (2, 2745, 5.0), (3, 61132, 3.0)]\n",
      "test       samples:  [(1, 2068, 2.5), (2, 260, 5.0), (2, 457, 5.0)]\n"
     ]
    }
   ],
   "source": [
    "training_rdd, validation_rdd, test_rdd = ratings_rdd.randomSplit([6, 2, 2], seed=14)\n",
    "\n",
    "print(f\"Training: {training_rdd.count()}, validation: {validation_rdd.count()}, test: {test_rdd      .count()}\")\n",
    "\n",
    "print(\"training   samples: \", training_rdd  .take(3))\n",
    "print(\"validation samples: \", validation_rdd.take(3))\n",
    "print(\"test       samples: \", test_rdd      .take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2bda0f-8a96-41ef-808f-c0714cbb8e0b",
   "metadata": {},
   "source": [
    "#### 2.2.2 Alternating Least Square Errors\n",
    "\n",
    "For movie recommendations, we start with a matrix whose entries are movie ratings by users.  Each column represents a user and each row represents a particular movie.\n",
    "\n",
    "Since not all users have rated all movies, we do not know all of the entries in this matrix, which is precisely why we need collaborative filtering.  For each user, we have ratings for only a subset of the movies.  With collaborative filtering, the idea is to approximate the rating matrix by factorizing it as the product of two matrices: one that describes properties of each user, and one that describes properties of each movie.\n",
    "\n",
    "We want to select these two matrices such that the error for the users/movie pairs where we know the correct ratings is minimized.  The *Alternating Least Squares* algorithm does this by first randomly filling the user matrix with values and then optimizing the value of the movies such that the error is minimized.  Then, it holds the movies matrix constant and optimizes the value of the user's matrix.  This alternation between which matrix to optimize is the reason for the \"alternating\" in the name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "767bfcef-d307-4dbe-a76a-ca4b25df68be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 09:41:26 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/02/22 09:41:26 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/02/22 09:41:27 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=141470, product=1732, rating=3.1807164083245922),\n",
       " Rating(user=18500, product=5621, rating=2.4928555764767624),\n",
       " Rating(user=18500, product=8533, rating=3.1193395535588895),\n",
       " Rating(user=18500, product=6763, rating=2.2404433916172453),\n",
       " Rating(user=18500, product=80363, rating=2.369844745977925)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "# thanks to modern libraries training an ALS model is as easy as\n",
    "model = ALS.train(training_rdd, rank = 4, seed = 14, iterations = 5, lambda_ = 0.1)\n",
    "\n",
    "# let's have a peek to few predictions\n",
    "model.predictAll(validation_rdd.map(lambda x:(x[0],x[1]))).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7bcf4e-e65a-4ed0-8b0d-6dd345a14e61",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.3 Root Mean Square Error (RMSE)\n",
    "\n",
    "Next, we need to evaluate our model: is it good or is it bad?\n",
    "\n",
    "To score the model, we will use RMSE (often called also Root Mean Square Deviation (RMSD)). You can think of RMSE as a distance function that measures the distance between the predictions and the ground truths. It is computed as follows: \n",
    "\n",
    "$$ RMSE(f, \\mathcal{D}) = \\sqrt{\\frac{\\sum_{(x,y) \\in \\mathcal{D}} (f(x) - y)^2}{|\\mathcal{D}|}}$$\n",
    "\n",
    "Where:\n",
    "* $\\mathcal{D}$ is our dataset it contains samples alongside their predictions. Formally, $\\mathcal{D} \\subseteq \\mathcal{X} \\times \\mathcal{Y}$. Where:\n",
    "    * $\\mathcal{X}$ is the set of all input samples.\n",
    "    * $\\mathcal{Y}$ is the set of all possible predictions. \n",
    "* $f : \\mathcal{X} \\rightarrow \\mathcal{Y}$ is the model we wish to evaluate. Given an input $x$ (from $\\mathcal{X}$, the set of possible inputs) it returns a value $f(x)$ (from $\\mathcal{Y}$, the set of possible outputs). \n",
    "* $x$ represents an input. \n",
    "* $f(x)$ represents the prediction of $x$.\n",
    "* $y$ represents the ground truth.\n",
    "\n",
    "As you can imagine $f(x)$ and $y$ can be different, i.e our model is wrong. With $RMSE(f, \\mathcal{D})$, we want to measure the degree to which our model, $f$, is wrong on the dataset $\\mathcal{D}$. The higher is $RMSE(f, \\mathcal{D})$ the higher is the degree to which $f$ is wrong. The smaller is $RMSE(f, \\mathcal{D})$ the more accurate $f$ is. \n",
    "\n",
    "To better understand the RMSE consider the following facts:\n",
    "* When $f(x)$ is close to $y$ our model is accurate. In the same case $(f(x) - y)^2$ is small.\n",
    "* When $f(x)$ is far from $y$ our model is inaccurate. In the same case $(f(x) - y)^2$ is high.\n",
    "* If our model is accurate, it will be often accurate in $\\mathcal{D}$. Therefore, it will make often small errors which will amount to a small RMSE. \n",
    "* If our model is inaccurate, it will be often inaccurate in $\\mathcal{D}$. Therefore, it will make often big errors which will amount to a large RMSE.\n",
    "\n",
    "Let's make a function to compute the RMSE so that we can use it multiple times easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e701e1bf-4bea-466a-8eb1-c6129b481f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RMSE(predictions_rdd, truths_rdd):\n",
    "    \"\"\" Compute the root mean squared error between predicted and actual\n",
    "    Args:\n",
    "        predictions_rdd: predicted ratings for each movie and each user where each entry is in the form (UserID, MovieID, Rating).\n",
    "        truths_rdd: actual ratings where each entry is in the form (UserID, MovieID, Rating).\n",
    "    Returns:\n",
    "        RSME (float): computed RSME value\n",
    "    \"\"\"\n",
    "    # Transform predictions and truths into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    predictions = predictions_rdd.map(lambda i: ((i[0], i[1]), i[2]))\n",
    "    truths      = truths_rdd     .map(lambda i: ((i[0], i[1]), i[2]))\n",
    "\n",
    "    # Compute the squared error for each matching entry (i.e., the same (User ID, Movie ID) in each\n",
    "    # RDD) in the reformatted RDDs using RDD transformtions - do not use collect()\n",
    "    squared_errors = predictions.join(truths)\\\n",
    "                                .map(lambda i: (i[1][0] - i[1][1])**2)\n",
    "                       \n",
    "\n",
    "    total_squared_error     = squared_errors.sum()\n",
    "    total_ratings           = squared_errors.count()\n",
    "    mean_squared_error      = total_squared_error / total_ratings\n",
    "    root_mean_squared_error = mean_squared_error ** (1/2)\n",
    "    \n",
    "    return root_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0220c3fc-3b4e-4ae9-b42f-49d9ab0277ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1882250104369456"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's evaluate the trained models\n",
    "\n",
    "RMSE(predictions_rdd = model.predictAll(validation_rdd.map(lambda x:(x[0],x[1]))),\n",
    "     truths_rdd      = validation_rdd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa900fdc-a69e-4593-bb5d-9757f011a4c1",
   "metadata": {},
   "source": [
    "#### 2.2.4 HyperParameters Tuning\n",
    "\n",
    "Can we do better? \n",
    "\n",
    "When training the ALS model there were few parameters to set. However, we do not know which is the best configuration. On these occasions, we want to try a few combinations to obtain even better results. In this section, we will search a few parameters. We will perform a so-called **grid search**. We will proceed as follows:\n",
    "\n",
    "1) We decide the parameters to tune.\n",
    "2) We train with all possible configurations. \n",
    "3) We evaluate a trained model with all possible configurations on the validation set.\n",
    "4) We evaluate the best model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "091981ea-d69f-46fe-93c4-46d1eda185e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best validation error 1.3506269717633657 with configuration {'rank': 4, 'seed': 14, 'iterations': 5, 'lambda': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best validation error 1.1882250104369456 with configuration {'rank': 4, 'seed': 14, 'iterations': 5, 'lambda': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best validation error 1.0803793995678013 with configuration {'rank': 4, 'seed': 14, 'iterations': 5, 'lambda': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best validation error 1.0295688329770294 with configuration {'rank': 4, 'seed': 14, 'iterations': 10, 'lambda': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best validation error 1.0281684455014197 with configuration {'rank': 8, 'seed': 14, 'iterations': 10, 'lambda': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3237:======================================>               (22 + 8) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 1.0285494437483655 with configuration {'rank': 8, 'seed': 14, 'iterations': 10, 'lambda': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "HyperParameters = {\n",
    "    \"rank\"       : [4, 8, 12],\n",
    "    \"seed\"       : [14],\n",
    "    \"iterations\" : [5, 10], \n",
    "    \"lambda\"     : [0.05, 0.1, 0.25]\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_error = float(\"inf\")\n",
    "best_conf  = dict()\n",
    "\n",
    "# how many training are we doing ?\n",
    "for rank in HyperParameters[\"rank\"]:                     #\n",
    "    for seed in HyperParameters[\"seed\"]:                 # I consider these nested for-loops an anti-pattern.\n",
    "        for iterations in HyperParameters[\"iterations\"]: # However, We can leave as it is for sake of simplicity. \n",
    "            for lambda_ in HyperParameters[\"lambda\"]:    # \n",
    "                \n",
    "                model = ALS.train(training_rdd, rank = rank, seed = seed, iterations = iterations, lambda_ = lambda_)\n",
    "                validation_error = RMSE(predictions_rdd = model.predictAll(validation_rdd.map(lambda x:(x[0],x[1]))),\n",
    "                                        truths_rdd      = validation_rdd)\n",
    "                \n",
    "                if validation_error < best_error: \n",
    "                    best_model, best_error = model, validation_error\n",
    "                    best_conf = {\"rank\":rank, \"seed\":seed, \"iterations\":iterations, \"lambda\":lambda_}\n",
    "                    print(f\"current best validation error {best_error} with configuration {best_conf}\")\n",
    "\n",
    "test_error = RMSE(predictions_rdd = model.predictAll(test_rdd.map(lambda x:(x[0],x[1]))), truths_rdd = test_rdd)\n",
    "print(f\"test error {test_error} with configuration {best_conf}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-RS",
   "language": "python",
   "name": "venv-rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
